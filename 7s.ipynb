{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahzad-r1zv1/LocalLLM_experiments/blob/main/7s.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pandas tqdm matplotlib reportlab python-pptx requests\n"
      ],
      "metadata": {
        "id": "xlMSHEIBQIpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================== ONE-CELL 7S + OLLAMA (COLAB, WRC EDITION) ==============================\n",
        "# Installs Ollama, pulls up to 3 models, runs selected 7S prompts across models (WRC wording),\n",
        "# consolidates results, and saves JSON/Markdown outputs in /content.\n",
        "\n",
        "import os, subprocess, shlex, time, requests, json, re, textwrap, datetime\n",
        "from typing import Dict, List\n",
        "\n",
        "# ---------------------------\n",
        "# 0) BASIC CONFIG (EDIT THESE)\n",
        "# ---------------------------\n",
        "# Organization inputs used to fill prompt placeholders\n",
        "ORG = {\n",
        "    \"name\": \"QA Automation Org\",\n",
        "    \"industry\": \"Software / DevTools\",\n",
        "    \"size_employees\": 180,\n",
        "    \"annual_revenue\": \"N/A (cost center)\",\n",
        "    \"locations\": \"Toronto; Remote\",\n",
        "    \"current_context\": \"Transitioning from phased QA to DevSecOps; aiming for predictive quality and CI/CD-first culture.\",\n",
        "    \"key_challenges\": \"Inconsistent test coverage; siloed defect data; unclear decision rights; skills gap in pipeline engineering.\",\n",
        "    \"recent_changes\": \"Trunk-based dev in 2 squads; feature flags/canary pilots; Playwright + contract tests on 2 critical APIs.\",\n",
        "    # Optional fields for specific prompts (leave as \"\" if unknown)\n",
        "    \"strategy_statement\": \"Ship faster with confidence via automated quality gates and proactive risk analytics.\",\n",
        "    \"strategic_goals\": \"12 months: 70% automated coverage; 24m: 95% critical path; MTTR<1hr; DORA elite.\",\n",
        "    \"kpis\": \"DORA metrics, escaped defect rate, mean time to detect, e2e reliability SLOs.\",\n",
        "    \"market_position\": \"Internal enablement platform within a large enterprise.\",\n",
        "    \"competitive_advantages\": \"Domain expertise; test data virtualization; unified telemetry.\",\n",
        "    \"target_segments\": \"Product teams building microservices/APIs.\",\n",
        "    \"value_proposition\": \"Fewer incidents, faster releases, higher trust in automation.\",\n",
        "    \"org_chart\": \"VP Eng → Dir QA/Platform → QA Enablement, SDET, Observability pods; squads map to product lines.\",\n",
        "    \"layers\": \"VP → Director → Managers → ICs (4 layers)\",\n",
        "    \"span_of_control\": \"Managers: 6-8 ICs avg\",\n",
        "    \"decision_rights\": \"Product owns scope; QA owns quality standards; Dev owns implementation; shared release gates.\",\n",
        "    \"xfunc\": \"Release Council; Reliability Guild; Architecture Forum.\",\n",
        "    \"geo\": \"Toronto hub + distributed remote\",\n",
        "    \"restructuring\": \"Evolving towards platform team model; decoupling test infra from app squads.\"\n",
        "}\n",
        "\n",
        "# Which prompts to run (choose from keys below)\n",
        "RUN_PROMPTS = [\n",
        "    \"PROMPT_1_FULL_7S\",\n",
        "    \"PROMPT_2_STRATEGY\",\n",
        "    \"PROMPT_3_STRUCTURE\",\n",
        "    \"PROMPT_4_SYSTEMS\",\n",
        "    \"PROMPT_5_SHARED_VALUES\",\n",
        "    \"PROMPT_6_SKILLS\",\n",
        "    \"PROMPT_7_STYLE\",\n",
        "    \"PROMPT_8_STAFF\",\n",
        "    \"PROMPT_9_ALIGNMENT\",\n",
        "    \"PROMPT_10_CHANGE\",\n",
        "    \"PROMPT_11_DIGITAL\",\n",
        "    \"PROMPT_12_BENCH\",\n",
        "    \"PROMPT_13_GAPS\",\n",
        "    \"PROMPT_14_INTEGRATION\",\n",
        "    \"PROMPT_15_EXEC_SUMMARY\",\n",
        "    \"MEGA_PROMPT\"\n",
        "]"
      ],
      "metadata": {
        "id": "Az5Pt0ZvjqiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Models to try pulling (we’ll use what actually succeeds), \"qwen3:8b\"\n",
        "# REQUESTED_MODELS = [\"qwen3\", \"mistral\", \"llama3\"]\n",
        "#REQUESTED_MODELS = [\"qwen3\", \"phi3\", \"llama3\"]\n",
        "# Common alias fixes (Ollama doesn't have \"gemma3\")\n",
        "# MODEL_ALIASES = {\n",
        "#     \"gemma3\": \"gemma2:9b-instruct\",\n",
        "#     \"gemma2-9b\": \"gemma2:9b-instruct\",\n",
        "#     \"gemma2-2b\": \"gemma2:2b-instruct\",\n",
        "#     \"gemma7b\": \"gemma:7b-instruct\",\n",
        "#     \"llama3.1\": \"llama3.1\",\n",
        "#      # pass-through example\n",
        "# }\n",
        "\n",
        "# # --- Pull models asynchronously ---\n",
        "# models = [\"mistral\", \"llama3\", \"gemma2:2b-instruct\"]  # use gemma2:2b or 9b instead of gemma3\n",
        "# models = [\"qwen3\", \"phi3\", \"llama3\"]\n",
        "\n",
        "MODEL_ALIASES = {\n",
        "    \"gemma3\": \"gemma2:9b-instruct\",\n",
        "    \"gemma2\": \"gemma2:2b-instruct\",\n",
        "    \"llama3\": \"llama3\",\n",
        "    \"llama3.1\": \"llama3.1\",\n",
        "    \"mistral\": \"mistral\",\n",
        "    \"phi4\":\"phi4\",\n",
        "    \"qwen3\" : \"qwen3:14b\",\n",
        "    \"gemma7b\": \"gemma:7b-instruct\",\n",
        "}\n",
        "REQUESTED_MODELS = [\"mistral\", \"llama3\", \"gemma2:9b-instruct\"]\n",
        "REQUESTED_MODELS = [MODEL_ALIASES.get(m.lower(), m) for m in REQUESTED_MODELS]\n",
        "\n",
        "# Output paths\n",
        "OUT_DIR = \"/content\"\n",
        "BUNDLE_JSON = os.path.join(OUT_DIR, \"7S_bundle.json\")\n",
        "REPORT_MD   = os.path.join(OUT_DIR, \"7S_report.md\")"
      ],
      "metadata": {
        "id": "Kgshbw4ajrmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 1️⃣ INSTALL & START OLLAMA (idempotent)\n",
        "# ---------------------------\n",
        "import subprocess, shlex, requests, time, os\n",
        "\n",
        "def run(cmd, check=True, quiet=False):\n",
        "    \"\"\"Run a shell command and optionally suppress output.\"\"\"\n",
        "    if isinstance(cmd, str):\n",
        "        cmd = shlex.split(cmd)\n",
        "    p = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "    if not quiet:\n",
        "        print(p.stdout.strip())\n",
        "    if check and p.returncode != 0:\n",
        "        raise RuntimeError(f\"CMD FAIL: {' '.join(cmd)}\\n----\\n{p.stdout}\")\n",
        "    return p.stdout.strip()\n",
        "\n",
        "def ollama_installed():\n",
        "    try:\n",
        "        out = run(\"ollama --version\", check=False, quiet=True)\n",
        "        return \"ollama\" in out.lower() or \"version\" in out.lower()\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def ollama_running():\n",
        "    try:\n",
        "        r = requests.get(\"http://127.0.0.1:11434/api/tags\", timeout=3)\n",
        "        return r.status_code == 200\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "# 1. Install Ollama if needed\n",
        "if ollama_installed():\n",
        "    print(\"✅ Ollama already installed.\")\n",
        "else:\n",
        "    print(\"📦 Installing Ollama…\")\n",
        "    run(\"bash -lc 'curl -fsSL https://ollama.com/install.sh | sh'\", check=False, quiet=True)\n",
        "    print(\"✅ Installation complete.\")\n",
        "\n",
        "# 2. Start Ollama service (if not already running)\n",
        "if ollama_running():\n",
        "    print(\"✅ Ollama service already running.\")\n",
        "else:\n",
        "    print(\"🚀 Starting ollama serve…\")\n",
        "    run(\"bash -lc 'pkill -f \\\"ollama serve\\\" || true'\", check=False, quiet=True)\n",
        "    log_path = \"/tmp/ollama.log\"\n",
        "    logf = open(log_path, \"w\")\n",
        "    proc = subprocess.Popen([\"ollama\", \"serve\"], stdout=logf, stderr=subprocess.STDOUT, text=True)\n",
        "\n",
        "    print(\"⏳ Waiting for Ollama to become ready\", end=\"\")\n",
        "    ready = False\n",
        "    for _ in range(60):\n",
        "        if ollama_running():\n",
        "            ready = True\n",
        "            break\n",
        "        print(\".\", end=\"\", flush=True)\n",
        "        time.sleep(2)\n",
        "    print()\n",
        "\n",
        "    if not ready:\n",
        "        print(\"⚠️ Ollama did not start. Showing last 30 log lines:\")\n",
        "        try:\n",
        "            print(\"\".join(open(log_path, \"r\", errors=\"ignore\").readlines()[-30:]))\n",
        "        except Exception:\n",
        "            pass\n",
        "        raise SystemExit(\"❌ Cannot continue without Ollama.\")\n",
        "    else:\n",
        "        print(\"✅ Ollama API ready at http://127.0.0.1:11434\")\n",
        "\n",
        "# Base endpoints\n",
        "BASE = \"http://127.0.0.1:11434\"\n",
        "TAGS = f\"{BASE}/api/tags\"\n",
        "CHAT = f\"{BASE}/api/chat\"\n",
        "GEN  = f\"{BASE}/api/generate\"\n",
        "print(f\"🌐 Connected to Ollama at {BASE}\")\n"
      ],
      "metadata": {
        "id": "piFQ0u-Gj0NQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 2️⃣ MODEL PULLER — fast, stable, quiet, verified\n",
        "# ---------------------------\n",
        "import subprocess, time, requests, os, sys\n",
        "\n",
        "\n",
        "\n",
        "def model_exists(model_name:str) -> bool:\n",
        "    \"\"\"Check if model already available locally.\"\"\"\n",
        "    try:\n",
        "        r = requests.get(\"http://127.0.0.1:11434/api/tags\", timeout=5)\n",
        "        if r.status_code == 200:\n",
        "            existing = {t[\"name\"] for t in r.json().get(\"models\", [])}\n",
        "            return any(model_name.startswith(x) or x.startswith(model_name) for x in existing)\n",
        "    except Exception:\n",
        "        return False\n",
        "    return False\n",
        "\n",
        "def pull_model(model_name:str, timeout:int=1200):\n",
        "    \"\"\"Pulls a model cleanly with short periodic output and timeout.\"\"\"\n",
        "    if model_exists(model_name):\n",
        "        print(f\"✅ {model_name} already available.\")\n",
        "        return True\n",
        "\n",
        "    print(f\"\\n📦 Pulling model: {model_name} (this may take several minutes)...\")\n",
        "    start = time.time()\n",
        "    env = os.environ.copy()\n",
        "    env[\"OLLAMA_EXPERIMENT\"] = \"client2\"\n",
        "\n",
        "    # Start process with streaming, minimal spam\n",
        "    process = subprocess.Popen(\n",
        "        [\"ollama\", \"pull\", model_name],\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.STDOUT,\n",
        "        text=True,\n",
        "        env=env\n",
        "    )\n",
        "\n",
        "    last_print = time.time()\n",
        "    buffer = []\n",
        "    while True:\n",
        "        line = process.stdout.readline()\n",
        "        if not line and process.poll() is not None:\n",
        "            break\n",
        "        if line:\n",
        "            buffer.append(line.strip())\n",
        "            # print every ~10s to avoid spam\n",
        "            if time.time() - last_print > 10:\n",
        "                sys.stdout.write(\".\")\n",
        "                sys.stdout.flush()\n",
        "                last_print = time.time()\n",
        "\n",
        "        # handle timeout\n",
        "        if time.time() - start > timeout:\n",
        "            print(f\"\\n⚠️ Timeout pulling {model_name}. Killing process.\")\n",
        "            process.kill()\n",
        "            break\n",
        "\n",
        "    rc = process.wait()\n",
        "    duration = int(time.time() - start)\n",
        "    print(f\"\\n✅ Pull complete for {model_name} (exit={rc}, {duration}s)\")\n",
        "\n",
        "    # quick verify\n",
        "    if not model_exists(model_name):\n",
        "        print(f\"⚠️ {model_name} not found after pull.\")\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "\n",
        "print(\"📥 Requesting models:\", \", \".join(REQUESTED_MODELS))\n",
        "available = []\n",
        "for m in REQUESTED_MODELS:\n",
        "    ok = pull_model(m)\n",
        "    if ok:\n",
        "        available.append(m)\n",
        "    else:\n",
        "        print(f\"⚠️ {m} failed; continuing.\")\n",
        "\n",
        "if not available:\n",
        "    raise SystemExit(\"❌ No models available after pulling. Try smaller ones like 'mistral'.\")\n",
        "\n",
        "PRIMARY_MODEL = available[0]\n",
        "print(\"\\n✅ Ready models:\", \", \".join(available))\n",
        "print(f\"⭐ Primary model: {PRIMARY_MODEL}\")\n"
      ],
      "metadata": {
        "id": "oFefbR2Bj-lI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Probe endpoints: prefer /api/chat, fallback to /api/generate\n",
        "# ---------------------------\n",
        "# Wait for Ollama API to settle before ping\n",
        "# ---------------------------\n",
        "print(\"🕐 Waiting for Ollama to settle after large model pulls...\")\n",
        "for i in range(30):  # ~90s total\n",
        "    try:\n",
        "        r = requests.get(TAGS, timeout=5)\n",
        "        if r.status_code == 200:\n",
        "            print(f\"✅ Ollama API responsive after {i*3}s\")\n",
        "            break\n",
        "    except Exception:\n",
        "        pass\n",
        "    time.sleep(3)\n",
        "else:\n",
        "    raise RuntimeError(\"❌ Ollama API never became responsive after 90s wait.\")\n",
        "\n",
        "# Try longer timeout for the first ping\n",
        "try:\n",
        "    pr = requests.post(\n",
        "        CHAT,\n",
        "        json={\"model\": PRIMARY_MODEL, \"messages\": [{\"role\": \"user\", \"content\": \"ping\"}], \"stream\": False},\n",
        "        timeout=60,\n",
        "    )\n",
        "    if pr.status_code == 404:\n",
        "        USE_GENERATE = True\n",
        "        print(\"ℹ️ Using /api/generate (chat not supported).\")\n",
        "    else:\n",
        "        USE_GENERATE = False\n",
        "        print(\"✅ /api/chat responsive.\")\n",
        "except Exception:\n",
        "    print(\"⚠️ /api/chat timed out; trying /api/generate instead…\")\n",
        "    gr = requests.post(\n",
        "        GEN,\n",
        "        json={\"model\": PRIMARY_MODEL, \"prompt\": \"ping\", \"stream\": False},\n",
        "        timeout=60,\n",
        "    )\n",
        "    if gr.status_code == 200:\n",
        "        USE_GENERATE = True\n",
        "        print(\"✅ /api/generate responsive.\")\n",
        "    else:\n",
        "        raise SystemExit(\"❌ Neither /api/chat nor /api/generate responded after model load.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "8hQzbxxBkDen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 3) PROMPT TEMPLATES (WRC wording)\n",
        "# ---------------------------\n",
        "def fill(s: str, kv: Dict[str,str]) -> str:\n",
        "    # simple replacement of [FIELD] with kv.get(field_lower)\n",
        "    def rep(m):\n",
        "        key = m.group(1).strip().lower().replace(\" \", \"_\")\n",
        "        return str(kv.get(key, f\"N/A: {m.group(0)}\"))\n",
        "    return re.sub(r\"\\[([^\\]]+)\\]\", rep, s)\n",
        "\n",
        "PROMPTS = {\n",
        "\"PROMPT_1_FULL_7S\": \"\"\"Act as a WRC (World Renowned Consultancy) consultant conducting a comprehensive 7S analysis.\n",
        "INPUTS NEEDED:\n",
        "- Company/Organization name: [NAME]\n",
        "- Industry: [INDUSTRY]\n",
        "- Company size (employees): [NUMBER]\n",
        "- Annual revenue: [REVENUE]\n",
        "- Geographic presence: [LOCATIONS]\n",
        "- Current business context: [BRIEF DESCRIPTION]\n",
        "- Key challenges facing the organization: [LIST 3-5]\n",
        "- Recent major changes or initiatives: [DESCRIBE]\n",
        "Analyze all seven elements:\n",
        "1. Strategy (competitive positioning, strategic priorities, value proposition)\n",
        "2. Structure (org design, reporting lines, decision rights)\n",
        "3. Systems (processes, IT systems, workflows)\n",
        "4. Shared Values (culture, core beliefs, mission/vision)\n",
        "5. Style (leadership approach, management practices)\n",
        "6. Staff (workforce composition, capabilities, engagement)\n",
        "7. Skills (organizational competencies, competitive advantages)\n",
        "OUTPUT FORMAT:\n",
        "- Executive summary with key findings\n",
        "- Detailed analysis of each S (current state assessment)\n",
        "- Interconnections and dependencies between elements\n",
        "- Alignment score (1-10) for each element pair\n",
        "- Top 5 misalignments requiring attention\n",
        "- Recommendations prioritized by impact and feasibility\n",
        "\"\"\",\n",
        "\"PROMPT_2_STRATEGY\": \"\"\"Evaluate the clarity and effectiveness of our organizational strategy using the 7S model.\n",
        "INPUTS NEEDED:\n",
        "- Current strategy statement: [PROVIDE]\n",
        "- Strategic goals (3-5 year): [LIST]\n",
        "- Key performance indicators: [LIST]\n",
        "- Market position: [DESCRIBE]\n",
        "- Competitive advantages: [LIST]\n",
        "- Target customer segments: [DESCRIBE]\n",
        "- Value proposition: [STATEMENT]\n",
        "Assess our strategy by examining:\n",
        "1. Clarity and communication throughout organization\n",
        "2. Alignment with market opportunities\n",
        "3. Differentiation from competitors\n",
        "4. Resource allocation alignment\n",
        "5. Measurability and tracking mechanisms\n",
        "6. Connection to other 6 S elements\n",
        "OUTPUT:\n",
        "- Strategy effectiveness score (1-10) with justification\n",
        "- Strengths and weaknesses analysis\n",
        "- Gaps between stated and actual strategy\n",
        "- Impact assessment on other 6 S elements\n",
        "- 5 specific recommendations to strengthen strategy\n",
        "- Communication plan to improve strategy understanding\n",
        "\"\"\",\n",
        "\"PROMPT_3_STRUCTURE\": \"\"\"Analyze our organizational structure's alignment with strategic goals.\n",
        "INPUTS NEEDED:\n",
        "- Current org chart: [DESCRIBE HIERARCHY]\n",
        "- Number of management layers: [NUMBER]\n",
        "- Span of control averages: [NUMBERS]\n",
        "- Decision-making authority levels: [DESCRIBE]\n",
        "- Cross-functional teams/committees: [LIST]\n",
        "- Geographic/divisional structure: [DESCRIBE]\n",
        "- Recent restructuring efforts: [DESCRIBE IF ANY]\n",
        "Evaluate:\n",
        "1. Structure-strategy fit\n",
        "2. Decision-making speed and effectiveness\n",
        "3. Communication flow efficiency\n",
        "4. Collaboration barriers\n",
        "5. Duplication or gaps in responsibilities\n",
        "6. Flexibility for future growth\n",
        "OUTPUT:\n",
        "- Structure effectiveness rating with evidence\n",
        "- Organizational design recommendations\n",
        "- Proposed org chart modifications\n",
        "- Impact analysis on systems and staff\n",
        "- Implementation roadmap for structural changes\n",
        "- Risk assessment of proposed changes\n",
        "\"\"\",\n",
        "\"PROMPT_4_SYSTEMS\": \"\"\"Assess the effectiveness of operational and management systems.\n",
        "INPUTS NEEDED:\n",
        "- Core business processes: [LIST]\n",
        "- IT systems and platforms: [LIST]\n",
        "- Performance management systems: [DESCRIBE]\n",
        "- Financial/budgeting processes: [DESCRIBE]\n",
        "- Quality control systems: [DESCRIBE]\n",
        "- Communication systems: [DESCRIBE]\n",
        "- Decision-making processes: [DESCRIBE]\n",
        "- Knowledge management systems: [DESCRIBE]\n",
        "Analyze:\n",
        "1. Process efficiency and effectiveness\n",
        "2. System integration and data flow\n",
        "3. Automation opportunities\n",
        "4. Performance tracking capabilities\n",
        "5. User satisfaction and adoption\n",
        "6. Alignment with strategic objectives\n",
        "OUTPUT:\n",
        "- Systems maturity assessment (1-5 scale per system)\n",
        "- Critical system gaps and redundancies\n",
        "- Process optimization opportunities\n",
        "- Technology upgrade recommendations\n",
        "- Implementation priority matrix\n",
        "- ROI estimates for system improvements\n",
        "\"\"\",\n",
        "\"PROMPT_5_SHARED_VALUES\": \"\"\"Identify and evaluate core shared values driving culture and decision-making.\n",
        "INPUTS NEEDED:\n",
        "- Stated mission/vision/values: [PROVIDE]\n",
        "- Employee survey results: [KEY FINDINGS]\n",
        "- Leadership behaviors observed: [EXAMPLES]\n",
        "- Decision-making patterns: [DESCRIBE]\n",
        "- Customer feedback themes: [SUMMARIZE]\n",
        "- Internal communication samples: [PROVIDE EXAMPLES]\n",
        "- Recognition and reward criteria: [LIST]\n",
        "Examine:\n",
        "1. Stated vs. lived values gap analysis\n",
        "2. Values alignment across hierarchy\n",
        "3. Values impact on behaviors\n",
        "4. Cultural strengths and toxicities\n",
        "5. Values-strategy alignment\n",
        "6. Employee value perception\n",
        "OUTPUT:\n",
        "- Core values identification (top 5 actual vs. stated)\n",
        "- Cultural health score with supporting evidence\n",
        "- Values-behavior alignment matrix\n",
        "- Cultural transformation requirements\n",
        "- Values reinforcement action plan\n",
        "- Measurement framework for cultural change\n",
        "\"\"\",\n",
        "\"PROMPT_6_SKILLS\": \"\"\"Evaluate critical skills and competencies across the organization.\n",
        "INPUTS NEEDED:\n",
        "- Current workforce skills inventory: [CATEGORIES]\n",
        "- Strategic capability requirements: [LIST]\n",
        "- Competitor capabilities: [BENCHMARK DATA]\n",
        "- Training and development programs: [DESCRIBE]\n",
        "- Performance review data: [KEY METRICS]\n",
        "- Skills gaps identified by managers: [LIST]\n",
        "- Future skill requirements (3-5 years): [ANTICIPATE]\n",
        "Assess:\n",
        "1. Current vs. required skills gaps\n",
        "2. Core competency strengths\n",
        "3. Competitive skill advantages/disadvantages\n",
        "4. Skills development effectiveness\n",
        "5. Knowledge transfer mechanisms\n",
        "6. Innovation and adaptation capabilities\n",
        "OUTPUT:\n",
        "- Skills heat map (current vs. required)\n",
        "- Critical skills gap analysis with risk levels\n",
        "- Competency development roadmap\n",
        "- Make/buy/partner talent decisions\n",
        "- L&D investment recommendations\n",
        "- Skills KPIs and tracking mechanisms\n",
        "\"\"\",\n",
        "\"PROMPT_7_STYLE\": \"\"\"Analyze the dominant leadership style and its impact on performance.\n",
        "INPUTS NEEDED:\n",
        "- Leadership team composition: [DESCRIBE]\n",
        "- Leadership assessment data: [IF AVAILABLE]\n",
        "- Employee engagement scores: [PROVIDE]\n",
        "- Decision-making examples: [3-5 CASES]\n",
        "- Communication patterns: [DESCRIBE]\n",
        "- Change management approaches: [EXAMPLES]\n",
        "- Succession planning status: [DESCRIBE]\n",
        "Evaluate:\n",
        "1. Predominant leadership styles\n",
        "2. Leadership effectiveness metrics\n",
        "3. Style-strategy alignment\n",
        "4. Leadership impact on culture\n",
        "5. Decision-making patterns\n",
        "6. Leadership development needs\n",
        "OUTPUT:\n",
        "- Leadership style profile with strengths/weaknesses\n",
        "- Leadership effectiveness score (1-10)\n",
        "- Style-situation fit analysis\n",
        "- Leadership development priorities\n",
        "- Succession planning recommendations\n",
        "- Leadership behavior change roadmap\n",
        "\"\"\",\n",
        "\"PROMPT_8_STAFF\": \"\"\"Review workforce composition, recruitment, and retention strategies.\n",
        "INPUTS NEEDED:\n",
        "- Total headcount and demographics: [PROVIDE]\n",
        "- Organizational structure by function: [BREAKDOWN]\n",
        "- Turnover rates by level/function: [DATA]\n",
        "- Time-to-fill metrics: [AVERAGES]\n",
        "- Employee engagement scores: [PROVIDE]\n",
        "- Compensation benchmarking: [POSITION VS MARKET]\n",
        "- Talent pipeline status: [DESCRIBE]\n",
        "- Diversity metrics: [PROVIDE]\n",
        "Analyze:\n",
        "1. Workforce composition vs. strategic needs\n",
        "2. Talent acquisition effectiveness\n",
        "3. Retention risks and drivers\n",
        "4. Engagement and productivity levels\n",
        "5. Diversity, equity, and inclusion status\n",
        "6. Workforce planning adequacy\n",
        "OUTPUT:\n",
        "- Workforce health scorecard\n",
        "- Critical talent risks and mitigation plans\n",
        "- Recruitment strategy optimization\n",
        "- Retention program enhancements\n",
        "- Workforce planning recommendations\n",
        "- HR metrics dashboard design\n",
        "\"\"\",\n",
        "\"PROMPT_9_ALIGNMENT\": \"\"\"Evaluate how well all seven elements of the 7S Framework align.\n",
        "INPUTS NEEDED:\n",
        "- Brief assessment of each S element: [PROVIDE STATUS]\n",
        "- Recent organizational changes: [LIST]\n",
        "- Performance metrics trends: [LAST 2 YEARS]\n",
        "- Strategic priorities: [TOP 5]\n",
        "- Known pain points: [DESCRIBE]\n",
        "- Success stories: [EXAMPLES]\n",
        "Assess:\n",
        "1. Element interdependencies and conflicts\n",
        "2. Alignment scoring for each element pair (21 combinations)\n",
        "3. Reinforcing vs. conflicting relationships\n",
        "4. Impact of misalignments on performance\n",
        "5. Root cause analysis of gaps\n",
        "6. Synergy opportunities\n",
        "OUTPUT:\n",
        "- 7S alignment matrix with scores\n",
        "- Critical misalignment identification\n",
        "- Dependency map visualization\n",
        "- Prioritized realignment initiatives\n",
        "- Change sequencing recommendations\n",
        "- Alignment monitoring framework\n",
        "\"\"\",\n",
        "\"PROMPT_10_CHANGE\": \"\"\"Use the 7S Framework to analyze organizational readiness for change.\n",
        "INPUTS NEEDED:\n",
        "- Planned change initiative: [DESCRIBE]\n",
        "- Change timeline and scope: [PROVIDE]\n",
        "- Previous change efforts: [SUCCESS/FAILURE EXAMPLES]\n",
        "- Stakeholder groups affected: [LIST]\n",
        "- Current change capability maturity: [ASSESS 1-5]\n",
        "- Resource availability: [BUDGET/PEOPLE]\n",
        "- Risk tolerance: [LOW/MEDIUM/HIGH]\n",
        "Analyze each S element for:\n",
        "1. Current state change readiness\n",
        "2. Required changes per element\n",
        "3. Resistance points and drivers\n",
        "4. Change capability gaps\n",
        "5. Success enablers and barriers\n",
        "6. Change impact assessment\n",
        "OUTPUT:\n",
        "- Change readiness score by S element\n",
        "- Resistance heat map\n",
        "- Change impact assessment matrix\n",
        "- Stakeholder engagement strategy\n",
        "- Change roadmap with quick wins\n",
        "- Risk mitigation plan\n",
        "- Success metrics framework\n",
        "\"\"\",\n",
        "\"PROMPT_11_DIGITAL\": \"\"\"Apply the 7S Framework to assess digital transformation readiness and impact.\n",
        "INPUTS NEEDED:\n",
        "- Current digital maturity: [ASSESS 1-5]\n",
        "- Digital strategy/initiatives: [DESCRIBE]\n",
        "- Technology infrastructure: [CURRENT STATE]\n",
        "- Digital skills inventory: [ASSESS]\n",
        "- Data and analytics capabilities: [DESCRIBE]\n",
        "- Customer digital expectations: [SUMMARIZE]\n",
        "- Competitor digital positioning: [BENCHMARK]\n",
        "Evaluate digital impact on:\n",
        "1. Strategy (digital business models)\n",
        "2. Structure (agile organization needs)\n",
        "3. Systems (technology architecture)\n",
        "4. Shared Values (digital culture)\n",
        "5. Style (digital leadership)\n",
        "6. Staff (digital talent)\n",
        "7. Skills (digital capabilities)\n",
        "OUTPUT:\n",
        "- Digital maturity assessment by S element\n",
        "- Digital transformation gaps and priorities\n",
        "- Technology investment recommendations\n",
        "- Digital culture transformation plan\n",
        "- Reskilling/upskilling requirements\n",
        "- Digital KPIs and governance model\n",
        "- Transformation roadmap with milestones\n",
        "\"\"\",\n",
        "\"PROMPT_12_BENCH\": \"\"\"Compare our 7S profile against key competitors.\n",
        "INPUTS NEEDED:\n",
        "- Top 3-5 competitors: [LIST]\n",
        "- Competitive intelligence available: [SUMMARIZE]\n",
        "- Industry best practices: [DESCRIBE]\n",
        "- Our performance vs. competitors: [METRICS]\n",
        "- Competitive advantages/disadvantages: [LIST]\n",
        "- Market position: [DESCRIBE]\n",
        "Benchmark:\n",
        "1. Strategy effectiveness comparison\n",
        "2. Organizational agility assessment\n",
        "3. Operational excellence comparison\n",
        "4. Cultural differentiation analysis\n",
        "5. Leadership capability comparison\n",
        "6. Talent competitiveness evaluation\n",
        "7. Innovation capability assessment\n",
        "OUTPUT:\n",
        "- Competitive 7S comparison matrix\n",
        "- Competitive advantage/disadvantage analysis\n",
        "- Best practice identification\n",
        "- Competitive gaps requiring closure\n",
        "- Differentiation opportunities\n",
        "- Competitive response strategies\n",
        "- Monitoring and intelligence framework\n",
        "\"\"\",\n",
        "\"PROMPT_13_GAPS\": \"\"\"Identify gaps between current and desired future state across the 7S elements.\n",
        "INPUTS NEEDED:\n",
        "- Vision for future state (3-5 years): [DESCRIBE]\n",
        "- Current state assessment: [SUMMARIZE BY S]\n",
        "- Strategic objectives: [LIST]\n",
        "- Performance targets: [SPECIFY]\n",
        "- Market/industry trends: [IDENTIFY]\n",
        "- Stakeholder expectations: [DESCRIBE]\n",
        "Analyze:\n",
        "1. Current state baseline for each S\n",
        "2. Future state requirements per S\n",
        "3. Gap magnitude and complexity\n",
        "4. Interdependency impact analysis\n",
        "5. Resource requirements for gap closure\n",
        "6. Timeline and sequencing needs\n",
        "OUTPUT:\n",
        "- Current vs. future state comparison table\n",
        "- Gap severity assessment (critical/high/medium/low)\n",
        "- Gap closure difficulty matrix\n",
        "- Investment requirements estimate\n",
        "- Transformation roadmap with phases\n",
        "- Quick wins vs. long-term initiatives\n",
        "- Success metrics and milestones\n",
        "\"\"\",\n",
        "\"PROMPT_14_INTEGRATION\": \"\"\"Combine 7S insights with SWOT or PESTLE analysis.\n",
        "INPUTS NEEDED:\n",
        "- 7S assessment summary: [PROVIDE]\n",
        "- SWOT analysis: [IF AVAILABLE]\n",
        "- PESTLE factors: [IF AVAILABLE]\n",
        "- Strategic options under consideration: [LIST]\n",
        "- Risk factors identified: [LIST]\n",
        "- Opportunity areas: [DESCRIBE]\n",
        "Integrate analyses to:\n",
        "1. Map external factors to internal capabilities\n",
        "2. Identify strategic option feasibility\n",
        "3. Assess implementation capabilities\n",
        "4. Determine competitive positioning\n",
        "5. Evaluate risk mitigation capacity\n",
        "6. Prioritize strategic initiatives\n",
        "OUTPUT:\n",
        "- Integrated strategy framework\n",
        "- Strategic option evaluation matrix\n",
        "- Capability-opportunity alignment map\n",
        "- Risk-readiness assessment\n",
        "- Strategic initiative prioritization\n",
        "- Implementation feasibility scores\n",
        "- Integrated dashboard design\n",
        "\"\"\",\n",
        "\"PROMPT_15_EXEC_SUMMARY\": \"\"\"Create an executive-level summary of 7S analysis with actionable recommendations.\n",
        "INPUTS NEEDED:\n",
        "- Full 7S analysis results: [PROVIDE KEY FINDINGS]\n",
        "- Strategic context and urgency: [DESCRIBE]\n",
        "- Available resources: [BUDGET/CAPACITY]\n",
        "- Board/Executive priorities: [LIST]\n",
        "- Key stakeholder concerns: [IDENTIFY]\n",
        "- Success criteria: [DEFINE]\n",
        "Synthesize:\n",
        "1. Critical insights from 7S analysis\n",
        "2. Top 3-5 strategic imperatives\n",
        "3. Quick wins vs. transformational changes\n",
        "4. Investment requirements and ROI\n",
        "5. Risk assessment and mitigation\n",
        "6. Implementation timeline\n",
        "OUTPUT:\n",
        "- 2-page executive summary\n",
        "- Visual 7S alignment dashboard\n",
        "- Top 10 recommendations ranked by impact\n",
        "- Investment and resource requirements\n",
        "- 90-day, 6-month, and 1-year action plans\n",
        "- Success metrics and governance model\n",
        "- Key risks and mitigation strategies\n",
        "- Next steps and decision requirements\n",
        "\"\"\",\n",
        "\"MEGA_PROMPT\": \"\"\"Act as a senior WRC consultant conducting a comprehensive 7S analysis. Provide a complete organizational assessment with actionable insights.\n",
        "[Use all context provided above and infer reasonable assumptions where N/A.]\n",
        "DELIVERABLES:\n",
        "- Executive Summary; Detailed Analysis by S; Integrated Findings; Strategic Recs; Implementation Plan; Appendices.\n",
        "\"\"\"\n",
        "}\n",
        "\n",
        "# Map bracketed placeholders to ORG fields\n",
        "PLACEHOLDER_MAP = {\n",
        "    \"[NAME]\": ORG.get(\"name\",\"\"),\n",
        "    \"[INDUSTRY]\": ORG.get(\"industry\",\"\"),\n",
        "    \"[NUMBER]\": ORG.get(\"size_employees\",\"\"),\n",
        "    \"[REVENUE]\": ORG.get(\"annual_revenue\",\"\"),\n",
        "    \"[LOCATIONS]\": ORG.get(\"locations\",\"\"),\n",
        "    \"[BRIEF DESCRIPTION]\": ORG.get(\"current_context\",\"\"),\n",
        "    \"[LIST 3-5]\": ORG.get(\"key_challenges\",\"\"),\n",
        "    \"[DESCRIBE]\": ORG.get(\"recent_changes\",\"\"),\n",
        "    \"[PROVIDE]\": ORG.get(\"strategy_statement\",\"\"),\n",
        "    \"[LIST]\": ORG.get(\"strategic_goals\",\"\"),\n",
        "    \"[STATEMENT]\": ORG.get(\"value_proposition\",\"\"),\n",
        "    \"[DESCRIBE HIERARCHY]\": ORG.get(\"org_chart\",\"\"),\n",
        "    \"[NUMBERS]\": ORG.get(\"span_of_control\",\"\"),\n",
        "    \"[IF AVAILABLE]\": \"\",\n",
        "    \"[AVERAGES]\": \"\",\n",
        "    \"[BREAKDOWN]\": \"\",\n",
        "    \"[DATA]\": \"\",\n",
        "    \"[POSITION VS MARKET]\": \"\",\n",
        "    \"[ASSESS 1-5]\": \"\",\n",
        "    \"[CURRENT STATE]\": \"\",\n",
        "    \"[ASSESS]\": \"\",\n",
        "    \"[SUMMARIZE]\": \"\",\n",
        "    \"[ANALYZE]\": \"\",\n",
        "    \"[IDENTIFY]\": \"\",\n",
        "    \"[SPECIFY]\": \"\"\n",
        "}\n",
        "\n",
        "def materialize_prompt(key: str) -> str:\n",
        "    text = PROMPTS[key]\n",
        "    for k,v in PLACEHOLDER_MAP.items():\n",
        "        text = text.replace(k, str(v if v else f\"N/A: {k}\"))\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "OsMRUxpNkI7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 4) OLLAMA CHAT HELPERS\n",
        "# ---------------------------\n",
        "TEMPERATURE, TOP_P, REPEAT_PENALTY, TIMEOUT_S = 0.4, 0.9, 1.1, 860\n",
        "\n",
        "def ask_llm(model: str, sys: str, user: str) -> str:\n",
        "    if USE_GENERATE:\n",
        "        prompt = f\"<<SYS>>\\n{sys}\\n<</SYS>>\\n\\n{user}\"\n",
        "        r = requests.post(GEN, json={\n",
        "            \"model\": model, \"prompt\": prompt, \"stream\": False,\n",
        "            \"options\": {\"temperature\": TEMPERATURE, \"top_p\": TOP_P, \"repeat_penalty\": REPEAT_PENALTY}\n",
        "        }, timeout=TIMEOUT_S)\n",
        "        r.raise_for_status()\n",
        "        return (r.json().get(\"response\") or \"\").strip()\n",
        "    else:\n",
        "        r = requests.post(CHAT, json={\n",
        "            \"model\": model,\n",
        "            \"messages\": [{\"role\":\"system\",\"content\":sys},{\"role\":\"user\",\"content\":user}],\n",
        "            \"stream\": False,\n",
        "            \"options\": {\"temperature\": TEMPERATURE, \"top_p\": TOP_P, \"repeat_penalty\": REPEAT_PENALTY}\n",
        "        }, timeout=TIMEOUT_S)\n",
        "        r.raise_for_status()\n",
        "        return ((r.json().get(\"message\") or {}).get(\"content\") or \"\").strip()\n",
        "\n",
        "def synthesize_consensus(primary_model: str, prompt_name: str, per_model: Dict[str,str]) -> str:\n",
        "    sys = \"You are a senior WRC consultant. Concisely synthesize multiple drafts into one coherent, non-redundant answer.\"\n",
        "    user = f\"\"\"Prompt: {prompt_name}\n",
        "Combine the following {len(per_model)} model answers into one clear, structured response.\n",
        "Write it in a report format without mentioning that this is a synthesized response.\n",
        "This will be going in front of Executives and VPs, so present it accordingly.\n",
        "- Keep the best points; remove repetition.\n",
        "- If answers conflict, state the trade-off and your recommendation.\n",
        "- Use short sections and bullets.\n",
        "\n",
        "=== ANSWERS ===\n",
        "{json.dumps(per_model, indent=2, ensure_ascii=False)}\n",
        "\"\"\"\n",
        "    return ask_llm(primary_model, sys, user)\n"
      ],
      "metadata": {
        "id": "MTKKxYIBkLgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 5) RUN SELECTED PROMPTS ACROSS MODELS\n",
        "# ---------------------------\n",
        "def run_prompt_across_models(prompt_key: str, models: List[str]) -> Dict[str,str]:\n",
        "    sys = \"You are precise and to-the-point.\"\n",
        "    usr = materialize_prompt(prompt_key)\n",
        "    out = {}\n",
        "    for m in models:\n",
        "        try:\n",
        "            txt = ask_llm(m, sys, usr)\n",
        "            out[m] = txt\n",
        "            print(f\"  ✓ {prompt_key} via {m}: {len(txt)} chars\")\n",
        "        except Exception as e:\n",
        "            out[m] = f\"(error from {m}: {e})\"\n",
        "            print(f\"  ✗ {prompt_key} via {m}: {e}\")\n",
        "    return out\n",
        "\n",
        "results = {}\n",
        "consensus = {}\n",
        "print(\"\\n🧠 Running prompts:\", \", \".join(RUN_PROMPTS))\n",
        "for key in RUN_PROMPTS:\n",
        "    per_model = run_prompt_across_models(key, available)\n",
        "    results[key] = per_model\n",
        "    consensus[key] = synthesize_consensus(PRIMARY_MODEL, key, per_model)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2GPkTylQUJt",
        "outputId": "117c9010-06dd-49b8-f2a4-9a31833162ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 Installing Ollama…\n",
            "🚀 Starting ollama serve…\n",
            "⏳ Waiting for Ollama to become ready.\n",
            "⏳ Waiting for Ollama API to respond…\n",
            "✅ Ollama API ready.\n",
            "📥 Pulling mistral (this can take 10–20 min in Colab)…\n",
            "📥 Pulling llama3 (this can take 10–20 min in Colab)…\n",
            "📥 Pulling gemma2:2b-instruct (this can take 10–20 min in Colab)…\n",
            "🕒 Now wait a few minutes before running analyses (pulls continue in background).\n",
            "📥 Pulling models (best-effort): qwen3, phi3, llama3\n",
            "⚙️ Using experimental client: OLLAMA_EXPERIMENT=client2\n",
            "\n",
            "⏳ Starting pull for qwen3:14b ...\n",
            "    \u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
            "    pulling a8cc1361f314: 100% ▕██████████████████▏ 9.3 GB                         \u001b[K\n",
            "    pulling ae370d884f10: 100% ▕██████████████████▏ 1.7 KB                         \u001b[K\n",
            "    pulling d18a5cc71b84: 100% ▕██████████████████▏  11 KB                         \u001b[K\n",
            "    pulling cff3f395ef37: 100% ▕██████████████████▏  120 B                         \u001b[K\n",
            "    pulling 78b3b822087d: 100% ▕██████████████████▏  488 B                         \u001b[K\n",
            "    verifying sha256 digest \u001b[K\n",
            "    writing manifest \u001b[K\n",
            "    success \u001b[K\u001b[?25h\u001b[?2026l\n",
            "✅ Finished pulling qwen3:14b in 0.2 seconds (exit 0)\n",
            "✅ Model qwen3:14b available and verified.\n",
            "\n",
            "⏳ Starting pull for phi3 ...\n",
            "    \u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
            "    pulling 633fc5be925f: 100% ▕██████████████████▏ 2.2 GB                         \u001b[K\n",
            "    pulling fa8235e5b48f: 100% ▕██████████████████▏ 1.1 KB                         \u001b[K\n",
            "    pulling 542b217f179c: 100% ▕██████████████████▏  148 B                         \u001b[K\n",
            "    pulling 8dde1baf1db0: 100% ▕██████████████████▏   78 B                         \u001b[K\n",
            "    pulling 23291dc44752: 100% ▕██████████████████▏  483 B                         \u001b[K\n",
            "    verifying sha256 digest \u001b[K\n",
            "    writing manifest \u001b[K\n",
            "    success \u001b[K\u001b[?25h\u001b[?2026l\n",
            "✅ Finished pulling phi3 in 0.2 seconds (exit 0)\n",
            "✅ Model phi3 available and verified.\n",
            "\n",
            "⏳ Starting pull for llama3 ...\n",
            "    \u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
            "    pulling 6a0746a1ec1a: 100% ▕██████████████████▏ 4.7 GB                         \u001b[K\n",
            "    pulling 4fa551d4f938: 100% ▕██████████████████▏  12 KB                         \u001b[K\n",
            "    pulling 8ab4849b038c: 100% ▕██████████████████▏  254 B                         \u001b[K\n",
            "    pulling 577073ffcc6c: 100% ▕██████████████████▏  110 B                         \u001b[K\n",
            "    pulling 3f8eb4da87fa: 100% ▕██████████████████▏  485 B                         \u001b[K\n",
            "    verifying sha256 digest \u001b[K\n",
            "    writing manifest \u001b[K\n",
            "    success \u001b[K\u001b[?25h\u001b[?2026l\n",
            "✅ Finished pulling llama3 in 0.2 seconds (exit 0)\n",
            "✅ Model llama3 available and verified.\n",
            "\n",
            "✅ Using models: qwen3:14b, phi3, llama3 (primary: qwen3:14b)\n",
            "🕐 Waiting for Ollama to settle after large model pulls...\n",
            "✅ Ollama API responsive after 0s\n",
            "✅ /api/chat responsive.\n",
            "\n",
            "🧠 Running prompts: PROMPT_1_FULL_7S, PROMPT_2_STRATEGY, PROMPT_3_STRUCTURE, PROMPT_4_SYSTEMS, PROMPT_5_SHARED_VALUES, PROMPT_6_SKILLS, PROMPT_7_STYLE, PROMPT_8_STAFF, PROMPT_9_ALIGNMENT, PROMPT_10_CHANGE, PROMPT_11_DIGITAL, PROMPT_12_BENCH, PROMPT_13_GAPS, PROMPT_14_INTEGRATION, PROMPT_15_EXEC_SUMMARY, MEGA_PROMPT\n",
            "  ✓ PROMPT_1_FULL_7S via qwen3:14b: 5670 chars\n",
            "  ✓ PROMPT_1_FULL_7S via phi3: 3924 chars\n",
            "  ✓ PROMPT_1_FULL_7S via llama3: 56 chars\n",
            "  ✓ PROMPT_2_STRATEGY via qwen3:14b: 3938 chars\n",
            "  ✓ PROMPT_2_STRATEGY via phi3: 4825 chars\n",
            "  ✓ PROMPT_2_STRATEGY via llama3: 47 chars\n",
            "  ✓ PROMPT_3_STRUCTURE via qwen3:14b: 3463 chars\n",
            "  ✓ PROMPT_3_STRUCTURE via phi3: 4482 chars\n",
            "  ✓ PROMPT_3_STRUCTURE via llama3: 33 chars\n",
            "  ✓ PROMPT_4_SYSTEMS via qwen3:14b: 6058 chars\n",
            "  ✓ PROMPT_4_SYSTEMS via phi3: 1880 chars\n",
            "  ✓ PROMPT_4_SYSTEMS via llama3: 33 chars\n",
            "  ✓ PROMPT_5_SHARED_VALUES via qwen3:14b: 5816 chars\n",
            "  ✓ PROMPT_5_SHARED_VALUES via phi3: 62801 chars\n",
            "  ✓ PROMPT_5_SHARED_VALUES via llama3: 33 chars\n",
            "  ✓ PROMPT_6_SKILLS via qwen3:14b: 3531 chars\n",
            "  ✓ PROMPT_6_SKILLS via phi3: 4491 chars\n",
            "  ✓ PROMPT_6_SKILLS via llama3: 33 chars\n",
            "  ✓ PROMPT_7_STYLE via qwen3:14b: 3750 chars\n",
            "  ✓ PROMPT_7_STYLE via phi3: 3070 chars\n",
            "  ✓ PROMPT_7_STYLE via llama3: 33 chars\n",
            "  ✓ PROMPT_8_STAFF via qwen3:14b: 2877 chars\n",
            "  ✓ PROMPT_8_STAFF via phi3: 4945 chars\n",
            "  ✓ PROMPT_8_STAFF via llama3: 366 chars\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 6) SAVE OUTPUTS\n",
        "# ---------------------------\n",
        "bundle = {\n",
        "    \"metadata\": {\n",
        "        \"generated_at_utc\": datetime.datetime.now(datetime.timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
        "        \"ollama_host\": BASE,\n",
        "        \"models\": available,\n",
        "        \"primary_model\": PRIMARY_MODEL\n",
        "    },\n",
        "    \"org_inputs\": ORG,\n",
        "    \"raw_per_prompt\": results,\n",
        "    \"consensus_per_prompt\": consensus\n",
        "}\n",
        "\n",
        "with open(BUNDLE_JSON, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(bundle, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "with open(REPORT_MD, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(f\"# 7S Report — Consensus (models: {', '.join(available)})\\n\\n\")\n",
        "    f.write(\"## Organization\\n\")\n",
        "    f.write(\"```json\\n\" + json.dumps(ORG, indent=2, ensure_ascii=False) + \"\\n```\\n\\n\")\n",
        "    for key in RUN_PROMPTS:\n",
        "        f.write(f\"## {key}\\n\\n\")\n",
        "        f.write(consensus.get(key,\"\").strip() + \"\\n\\n\")\n",
        "        f.write(\"<details><summary>Model answers</summary>\\n\\n\")\n",
        "        f.write(\"```json\\n\" + json.dumps(results.get(key,{}), indent=2, ensure_ascii=False) + \"\\n```\\n\")\n",
        "        f.write(\"</details>\\n\\n\")\n",
        "\n",
        "print(\"\\n✅ Done.\")\n",
        "print(\"JSON:\", BUNDLE_JSON)\n",
        "print(\"MD  :\", REPORT_MD)\n",
        "# =========================================================================================="
      ],
      "metadata": {
        "id": "VGhMDIGilhLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================= DISPLAY 7S REPORT IN-CELL =======================\n",
        "import os, json, textwrap\n",
        "from IPython.display import display, Markdown, HTML\n",
        "\n",
        "OUT_DIR = \"/content\"\n",
        "BUNDLE_JSON = os.path.join(OUT_DIR, \"7S_bundle.json\")\n",
        "REPORT_MD   = os.path.join(OUT_DIR, \"7S_report.md\")\n",
        "\n",
        "def _h2(s):\n",
        "    return f\"\\n## {s}\\n\"\n",
        "def _h3(s):\n",
        "    return f\"\\n### {s}\\n\"\n",
        "def _codeblock(label, obj):\n",
        "    if isinstance(obj, str):\n",
        "        body = obj\n",
        "    else:\n",
        "        body = json.dumps(obj, indent=2, ensure_ascii=False)\n",
        "    return f\"\\n**{label}**\\n\\n```json\\n{body}\\n```\\n\"\n",
        "\n",
        "# 1) If the Markdown report exists, render that directly (richest output)\n",
        "if os.path.exists(REPORT_MD):\n",
        "    with open(REPORT_MD, \"r\", encoding=\"utf-8\") as f:\n",
        "        md = f.read()\n",
        "    display(Markdown(md))\n",
        "else:\n",
        "    # 2) Otherwise, pretty-print from the JSON bundle\n",
        "    if not os.path.exists(BUNDLE_JSON):\n",
        "        raise FileNotFoundError(\"No report found. Run the main cell first to create /content/7S_bundle.json or /content/7S_report.md.\")\n",
        "\n",
        "    with open(BUNDLE_JSON, \"r\", encoding=\"utf-8\") as f:\n",
        "        bundle = json.load(f)\n",
        "\n",
        "    meta     = bundle.get(\"metadata\", {})\n",
        "    org      = bundle.get(\"org_inputs\", {})\n",
        "    consensus = bundle.get(\"consensus_per_prompt\", {})\n",
        "    raw       = bundle.get(\"raw_per_prompt\", {})\n",
        "\n",
        "    # Build a friendly Markdown view\n",
        "    parts = []\n",
        "    title = f\"# 7S Report — Consensus (models: {', '.join(meta.get('models', []))})\"\n",
        "    parts.append(title)\n",
        "    parts.append(_h2(\"Organization\"))\n",
        "    parts.append(\"```json\\n\" + json.dumps(org, indent=2, ensure_ascii=False) + \"\\n```\")\n",
        "\n",
        "    # Show consensus outputs section-by-section\n",
        "    for k in consensus.keys():\n",
        "        parts.append(_h2(k))\n",
        "        txt = consensus.get(k, \"\").strip()\n",
        "        if not txt:\n",
        "            parts.append(\"_No consensus text produced for this prompt._\")\n",
        "        else:\n",
        "            # Light formatting: ensure lines not too long for the notebook width\n",
        "            wrapped = \"\\n\".join(textwrap.fill(line, width=100) for line in txt.splitlines())\n",
        "            parts.append(wrapped)\n",
        "\n",
        "        # Collapsible raw model answers\n",
        "        parts.append(\"\\n<details><summary>Model answers</summary>\\n\\n\")\n",
        "        parts.append(\"```json\\n\" + json.dumps(raw.get(k, {}), indent=2, ensure_ascii=False) + \"\\n```\")\n",
        "        parts.append(\"\\n</details>\\n\")\n",
        "\n",
        "    display(Markdown(\"\\n\".join(parts)))\n",
        "# ========================================================================\n"
      ],
      "metadata": {
        "id": "SbVDZhmPGOgO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}